#!/bin/sh
conda activate virsci

CUDA_VISIBLE_DEVICES=0 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11434 ollama serve &
CUDA_VISIBLE_DEVICES=0 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11435 ollama serve &
CUDA_VISIBLE_DEVICES=0 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11436 ollama serve &
CUDA_VISIBLE_DEVICES=1 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11437 ollama serve &
CUDA_VISIBLE_DEVICES=1 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11438 ollama serve &
CUDA_VISIBLE_DEVICES=1 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11439 ollama serve &
CUDA_VISIBLE_DEVICES=1 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11440 ollama serve &
CUDA_VISIBLE_DEVICES=2 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11441 ollama serve &
CUDA_VISIBLE_DEVICES=2 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11442 ollama serve &
CUDA_VISIBLE_DEVICES=2 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11443 ollama serve &
CUDA_VISIBLE_DEVICES=2 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11444 ollama serve &
CUDA_VISIBLE_DEVICES=3 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11445 ollama serve &
CUDA_VISIBLE_DEVICES=3 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11446 ollama serve &
CUDA_VISIBLE_DEVICES=3 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11447 ollama serve &
CUDA_VISIBLE_DEVICES=3 OLLAMA_CONTEXT_LENGTH=8192 OLLAMA_HOST=0.0.0.0:11448 ollama serve &


python -m vllm.entrypoints.openai.api_server \
    --model MODEL/Qwen3-235B-A22B-Thinking-2507-FP8 \
    --tensor-parallel-size 4 \
    --port 8000 \
    --gpu-memory-utilization 0.9 \
    --trust-remote-code

cd AI-Collaboration-Disruption/Virtual-Scientists-v2-main
python run_fast.py 2>&1 | tee virsci_output.txt
